# Ball Tracking Robot 
We have robots that move using controllers, robots that move using gestures, and robots that move 

| **Engineer** | **School** | **Area of Interest** | **Grade** |
|:--:|:--:|:--:|:--:|
| Lorelei Xia | Irvington High School | Electrical Engineering | Rising Junior

![Headstone Image](https://bluestampengineering.com/wp-content/uploads/2016/05/improve.jpg)

# Third Milestone 

For my final milestone, I was able to begin working on the hardware portion of my robot! I began with setting up the switch to the battery pack, but soon realized that after attempting to power the h-bridge motor controller to the switch, it wouldn't turn on. After moving around the wires, attempting to resolve the problem, I decided to instead plug in jumper wires directly to the positive and negative ends fo the batteries, which fortunately powered the motor controller. To set up the camera module, I used an extra breadboard and taped it to the front of the robot, sticking the camera to the frontside of the breadboard. Then, I used a code where the robot would move to the right or left depending on the position of the ball in the camera frame. When the robot feels as if the ball is near the center of the frame, it would stop. However, this led to the problem where the robot would move in random directions if the ball wasn't in the frame at all. Therefore, I added in a few lines of code where if the robot did not detect any of the threholded colors in the frame, it would move to the left. Another problem soon arised, as the robot would detect small spots of colors and stop. As a result, I set up code where the robot would only stop if the number of pixels that it detects are within the color threshold is greater than a certain number. Finally, my ball tracking robot is finished! Inf the future, I hope to make my robot move towards the ball depending on how far the robot is!

# Second Milestone 

My second milestone was finalizing the code for the raspberry pi to detect and record the coordinates of the object I want it to detect. Originally, I had done some research on using opencv to track shapes (as the object I want my robot to detect is a ball), however, after going through a few attempts at incorporating the shape detecting code, we found that detecting colors was a lot more straightforward and easy to incorporate/use. I decided to use the HSV color model to pick specific color ranges for my object, as it is much more easier to understand and choose the right colors than using a RGB model. I first began with defining hue, saturation, and value, as the values that you are given when choosing colors with an online color picker are different to the values that is printed when my I run my code. I then added a threshold range of values, so the robot would be able to block out the object that I want it to detect. The colors that I want the robot to detect would be white in the binary image, and the colors outside of the designated threshold would be black. Then, I set up a series of code that would create a reticle in the center of the colors that the robot thinks is within the threshold values. After finalizing these codes, my robot was able to detect and pinpoint any object of my desires!

# First Milestone
  
My first milestone was setting up and hooking up the Raspberry Pi to my computer. Then I downloaded VNC, which is a computer software that allows me to access the raspberry pi environment. In VNC, I can write out programs directly to the raspberry pi for it to execute my commands. Because my project requires the use of a camera, I began hooking up a camera module to the raspberry pi. Then, I ran a sample code in the raspberry pi enviroment to test the camera module, and it was able to produce excellent colored images. However, the lag in the enviroment was extremely exasperating. To maneuver around the raspberry pi environment lag, I downloaded Visual Studio code onto my computer and connected it to my raspberry pi. This allows me to write out and run raspberry pi commands directly on my computer, wihtout having to take the extra time to open VNC and the raspberry pi environment. My project uses computer vision to track a moving ball, so we began working on a code that would outline the contours in an image. For my next milestone, I hope to be able to construct my robot, and work out a code that would allow the raspberry pi to detect and outline specific shapes in a RGB image. 

[![First Milestone](https://res.cloudinary.com/marcomontalbano/image/upload/v1612574117/video_to_markdown/images/youtube--CaCazFBhYKs-c05b58ac6eb4c4700831b2b3070cd403.jpg)](https://www.youtube.com/watch?v=CaCazFBhYKs "First Milestone"){:target="_blank" rel="noopener"}
